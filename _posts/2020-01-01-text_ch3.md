---
layout: post
title:  "[파이썬] 파이썬으로 배우는 응용텍스트 분석 (Ch3. 말뭉치의 전처리와 가공)"
subtitle:   "PYTHON"
categories: pro
tags: python
comments: true
---


파이썬으로 배우는 응용텍스트 분석 (Ch3. 말뭉치의 전처리와 가공) (P41 ~ P58까지 ) 

<img src="http://image.yes24.com/momo/TopCate2739/MidCate008/273872383.jpg" width="30%">  

---


# CH3. 말뭉치의 전처리와 가공

- 수집된 원시 텍스트를 계산하고 모델링을 하기 좋은 형태에 맞게 체계적으로 변환하는 데 사용할 수 있는 **다목적 전처리 프레임워크**를 제안
- 5가지 (내용 추출, 단락 블록 지정, 문장 분할, 단어 토큰화 및 품사태깅)을 포함한 프레임워크

## 문서 쪼개 보기
  
### 핵심 내용 식별 및 추출
- HTML은 예측 불가능성으로 인해 데이터 추출이 무척 어렵다.
- Readablility-lxml 라이브러리는 웹에서 수집된 문서를 다루기에 좋음 (페이지 내용에서 잡다한 것들을 제거해 텍스트만 남김)
- 일련의 정규식을 사용하여 탐색 모음, 광고, 페이지 스크립트 태그 및 CSS(Cascading Style Sheet, 디자인 요소)를 제거하여 새로운 문서 객체 모델(DOM, document object model)을 통해 텍스트를 재구성 한다.
  
### 문서를 단락별로 나누기
- PlaintextCorpusReader와 같은 일부 NLTK 말뭉치 리더는 paras()메서드를 구현하여 이중 줄바꿈으로 구분된 텍스트 블록으로 정의된 단락을 생성
- HTML 태그의 <p>태그를 검색해 내용을 격리시킬수 있다.
- BeautifulSoup를 사용해 HTML에서 단락들을 구분분석한다.
  
### 분할 : 문장별로 나누기
- paras()를 감싼 단락을 sents() 메서드로 각 문장을 반환
- send_tokenize는 PunktSentenceTokenizer를 사용하는데 이 토크나이저는 시작과 끝을 알리는 단어와 구두점(ex. 마침표, 물음표, 느낌표, 대문자 등)ㅇ을 배운 사전 훈련 모델이다.
- 그러나 식별하기 쉽지않을 경우도 많기 때문에 반드시 유요한 결과를 얻을 수 있다고 기대하기는 어렵다.

### 토큰화 : 개별 토큰 식별
- 텍스트에서 공백과 구두점을 모두 떼어내고 영문자 및 비영문자 목록을 반환하는 정규 표현식 기반 토크나이저인 WordPunctTokenizer를 사용
- ex. 하이픈으로 연결해 만든 단어를 합성어(compound)로 봐야하는가 떼어서 봐야하는가?, 축약형(contraction)을 토큰 한개 또는 두개로 접근하는가에 대한 문제가 있음
- word_tokenize를 사용하여 텍스트 토큰화를 한다.

### 품사 태깅
- 동사, 명사, 전치사, 형용사 등을 태그한다.
- pos_tag를 사용 (그안의 펜 트리뱅크 태그셋(36개 품사와 구조적 태그) 사용)

### 중간 말뭉치 분석론
- describe() 메서드를 추가해서 변화하는 범주, 어휘 및 복잡성에 대한 중간 말뭉치 분석을 수행
- (1)파일 및 범주의 총수 (2)단락, 문장 및 단어의 총 수 및 고유 용어의 수 (3)어휘적 다양성(전체 단어에 대한 고유 용어의 비율) (4)문서당 평균 단락수 (5)단락당 평균 문장 수 (6)총 처리 시간
  
## 말뭉치 변환
- 원시 말뭉치 -> HTMLCorpusReader -> 전처리기 -> 전처리를 한 말뭉치 -> 피클링 처리한 말뭉치 리더 -> 벡터라이저 -> 모델러
- 여기서 Preprocessor(전처리기) 클래스는 중간 변환된 말뭉치를 저장, PickledCorpusReader(피클링 처리한 말뭉치 리더)는 벡터화를 위해 표준화된 방식의 변환된 문서를 디스크에서 스트리밍
- 이렇게 함으로써 하이퍼파라미터 세터를 테스트할때마다 전처리를 할 필요가 없다.
  
### 중간 전처리 및 저장
- 전처리를 작성하고 전처리가 밟는 단계들을 실행, 새 텍스트 말뭉치를 디스크에 작성

### 피클링 처리를 위해 쓰기
- 전처리된 말뭉치를 변형하고 저장하기 위한 옵션으로 피클(pickle)을 사용)
- 한 번에 하나의 문서를 메모리에 적재(load)하고 대상 데이터 구조로 변환한 다음 디스크의 작은 파일에 덤프하는 이터레이터(반복자)를 작성
- 사람이 읽을 수는 없지만 압축되고 적재하기 쉽게 직렬화(serialize)되거나 직렬해제(deserialize)되어 매우 효율 

### 처리된 말뭉치 읽기
- 피클링한(압축되고 전처리되어 절여진) 말뭉치가 있으면 토큰화 메서드들이나 구문분석을 다시 적용할 필요 없이 엑세스 할 수 있다.
- 말뭉치를 읽으려면 pickle.load() 사용해 한 번에 한 문서를 빠르게 검색하는 PickledCorpusReader가 필요하다.
